{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "348efe30-5b97-4050-8a51-ca14a8de5833",
   "metadata": {},
   "source": [
    "<p style=\"float:right\"> <img src=\"assets/orange.png\" alt=\"Orange logo\" width=\"40\" /> <img src=\"assets/ulb.jpg\" alt=\"ULB logo\" width=\"40\" /> <img src=\"assets/mlg.png\" alt=\"MLG logo\" width=\"160\" /> <img src=\"assets/innoviris.jpg\" alt=\"Innoviris logo\" width=\"200\" /></p>\n",
    "\n",
    "**_Notebook for the AppliedPhD project Machu-Picchu written by Th√©o Verhelst_**<br/>\n",
    "_Supervisors at Orange: Denis Mercier, Jeevan Shrestha_<br/>\n",
    "_Academic supervision: Gianluca Bontempi (ULB MLG)_\n",
    "# Simulating uplift modeling with a Dirichlet distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9259fb9d-ac48-4dd4-9f14-afafb2d010af",
   "metadata": {},
   "source": [
    "First, some imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9db2bf9-001d-4603-8229-5273a4212fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "from math import ceil\n",
    "import pickle\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import stats as st\n",
    "from scipy.special import digamma\n",
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "import seaborn as sns\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm.autonotebook import trange\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "from functions.simulation_functions import simulate_uplift_dirichlet\n",
    "from functions.eval_measures import cf_profit_curve\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "plt.rcParams[\"mathtext.fontset\"] = \"dejavuserif\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3221ed74-eff3-49a8-b712-a79d7c09a448",
   "metadata": {},
   "source": [
    "This function is used to format plot titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ec9e64-095b-4b47-b309-fcc4e30d5041",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_number(x, precision):\n",
    "    res = np.format_float_positional(x, precision=precision, trim=\"-\", fractional=True)\n",
    "    if res.endswith(\".\"):\n",
    "        res = res[:-1]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9610e048-5b46-47c4-8412-5cd3068fb61d",
   "metadata": {},
   "source": [
    "## Testing the code on a single simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdcf262-dd65-457a-bc6b-2576135e1785",
   "metadata": {},
   "source": [
    "As a preliminary step, we run the simulation once with fixed parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe0a0db-c3c7-4d26-b003-0123320d2793",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.array([0.9, 0.05, 0.03, 0.02])\n",
    "S_0 = mu[1] + mu[3]\n",
    "S_1 = mu[2] + mu[3]\n",
    "A = 80\n",
    "a = A * mu\n",
    "size = 100000\n",
    "var_p = 0.003\n",
    "var_u = 0.01\n",
    "n_p_0 = 60\n",
    "n_u_0 = 20\n",
    "n_u_1 = 20\n",
    "data = simulate_uplift_dirichlet(a, size, n_p_0, n_u_0, n_u_1)\n",
    "\n",
    "prior_entropy = -np.sum(mu * np.log2(mu))\n",
    "posterior_entropy = digamma(A + 1) - np.sum(digamma(a + 1) * a) / A\n",
    "mutual_info = prior_entropy - posterior_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13565a7f-01f5-4cfc-99af-9256ca3562d4",
   "metadata": {},
   "source": [
    "Let's compute the mutual information between the outcomes and the emulated features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab79dbea-4d28-4b92-924a-78ae8fc2bf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "I_0 = st.entropy([S_0, 1 - S_0])\n",
    "I_0_X = np.mean(st.entropy(np.array([data.S_0, 1 - data.S_0]), axis=0))\n",
    "I_1 = st.entropy([S_1, 1 - S_1])\n",
    "I_1_X = np.mean(st.entropy(np.array([data.S_1, 1 - data.S_1]), axis=0))\n",
    "print(\"Percentage of mutual information I(X; Y_0): {:.4%}\".format(1 - I_0_X/I_0))\n",
    "print(\"Percentage of mutual information I(X; Y_1): {:.4%}\".format(1 - I_1_X/I_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96ad3aa-72e6-448d-9474-59af8ae4b937",
   "metadata": {},
   "outputs": [],
   "source": [
    "curve_u = cf_profit_curve(data[\"uplift_hat\"], data[\"S_0\"], data[\"S_1\"])\n",
    "curve_p = cf_profit_curve(data[\"S_0_hat\"], data[\"S_0\"], data[\"S_1\"])\n",
    "plt.plot(curve_u[\"k\"], curve_u[\"profit\"], label=\"uplift\")\n",
    "plt.plot(curve_p[\"k\"], curve_p[\"profit\"], label=\"proba\")\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"Profit\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9919577b-1826-4d36-b303-8bb7fe392fc5",
   "metadata": {},
   "source": [
    "## Define the function that evaluates a simulation run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1611d1c5-4771-4f3f-97a8-a1aede1a8d96",
   "metadata": {},
   "source": [
    "This function computes all the statistics that we will report from the full experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70008f1-01cc-484c-a203-bfe149fe7fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_uplift_proba_dirichlet(mu, A, size, n_p_0, n_u_0, n_u_1,\n",
    "                               CB=np.array([[1, 1], [0, 0]]),\n",
    "                               use_churn_convention=True):\n",
    "    a = A * mu\n",
    "    data = simulate_uplift_dirichlet(a, size, n_p_0, n_u_0, n_u_1,\n",
    "                                 use_churn_convention=use_churn_convention)\n",
    "    \n",
    "    prior_entropy = -np.sum(mu * np.log(mu))\n",
    "    posterior_entropy = digamma(A + 1) - np.sum(digamma(a + 1) * a) / A\n",
    "    mutual_info = prior_entropy - posterior_entropy\n",
    "    \n",
    "    curve_u = cf_profit_curve(data.uplift_hat, data.S_0, data.S_1, CB)\n",
    "    curve_p = cf_profit_curve(data.S_0_hat, data.S_0, data.S_1, CB)\n",
    "    auuc_u = np.mean(curve_u.profit)\n",
    "    auuc_p = np.mean(curve_p.profit)\n",
    "    var_p = np.mean(data.S_0 * (1 - data.S_0) / n_p_0)\n",
    "    var_u = np.mean(data.S_0 * (1 - data.S_0) / n_u_0 + data.S_1 * (1 - data.S_1) / n_u_1)\n",
    "\n",
    "    eps_auuc = 0.000001\n",
    "    if np.abs(auuc_u - auuc_p) <= eps_auuc:\n",
    "        best_approach = \"e\"\n",
    "    elif auuc_u > auuc_p:\n",
    "        best_approach = \"u\"\n",
    "    else:\n",
    "        best_approach = \"p\"\n",
    "    \n",
    "    return {\n",
    "        \"alpha\": mu[0], \"beta\" : mu[1], \"gamma\": mu[2], \"delta\": mu[3],\n",
    "        \"A\": A,\n",
    "        \"CB_00\": CB[0, 0], \"CB_01\": CB[0, 1], \"CB_10\": CB[1, 0], \"CB_11\": CB[1, 1],\n",
    "        \"a_0\": a[0], \"a_1\": a[1], \"a_2\": a[2], \"a_3\": a[3],\n",
    "        \"S_0\": mu[1] + mu[3],\n",
    "        \"S_1\": mu[2] + mu[3],\n",
    "        \"size\": size,\n",
    "        \"prior_entropy\": prior_entropy,\n",
    "        \"posterior_entropy\": posterior_entropy,\n",
    "        \"mutual_info\": mutual_info,\n",
    "        \"n_p_0\": n_p_0,\n",
    "        \"n_u_0\": n_u_0,\n",
    "        \"n_u_1\": n_u_1,\n",
    "        \"var_p\": var_p,\n",
    "        \"var_u\": var_u,\n",
    "        \"auuc_u\": auuc_u,\n",
    "        \"auuc_p\": auuc_p,\n",
    "        \"auuc_d\": auuc_u - auuc_p,\n",
    "        \"best_approach\": best_approach\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19635928-3a8c-4616-9134-13c43cc5233b",
   "metadata": {},
   "source": [
    "This function converts a long format dataframe to a color matrix displayable with plt.imshow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9b3ea5-2f5a-4487-b52c-458a042405a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_to_color_matrix(df, rows, columns, values, cmap):\n",
    "    df = df[[rows, columns, values]].pivot(index=rows, columns=columns)[values].to_numpy()\n",
    "    # Add a third dimension for specifying the color\n",
    "    df = np.expand_dims(df, 2).repeat(3, 2)\n",
    "    # Fill with the colors\n",
    "    for i in range(df.shape[0]):\n",
    "        for j in range(df.shape[1]):\n",
    "            for value, color in cmap.items():\n",
    "                if df[i, j, 0] == value:\n",
    "                    df[i, j, :] = color\n",
    "    return df.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4be83b6-b60b-4af2-8325-4867aedf6e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = {\n",
    "    \"u\": (31, 119, 180),\n",
    "    \"p\": (255,127,14),\n",
    "    \"e\": (148,103,189)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39dd11c6-a50a-45a4-a1e7-43dc9da63704",
   "metadata": {},
   "source": [
    "## Experiments\n",
    "### Impact of mutual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47834833-3cf8-4d6a-a708-d7883a1960b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs = 6000\n",
    "#mu = st.dirichlet.rvs(np.array([0.4, 0.2, 0.2, 0.2]) * 30, size=n_runs)\n",
    "mu = np.array([0.6, 0.2, 0.1, 0.1])\n",
    "\n",
    "# Values selected to have information rate of 0, 0.01, 0.1, 0.9, 0.99 and 1\n",
    "steps_A = np.array([\n",
    "    1e10,      # I = 0%\n",
    "    1365.0078, # I = 0.1%\n",
    "    136.3132,  # I = 1%\n",
    "    44.22273980505,  # I = 3%\n",
    "    12.24227,  # I = 10%\n",
    "    0.128356,  # I = 90%\n",
    "    #0.01154,  # I = 99%\n",
    "    #1e-4      # I = 100%\n",
    "])\n",
    "#A = 10**st.uniform.rvs(-4, 7, size=n_runs)\n",
    "size = 500000\n",
    "params = ParameterGrid({\n",
    "    \"A\": steps_A,\n",
    "    \"n_p_0\": range(1, 51),\n",
    "    \"n_u_0\": range(1, 51)\n",
    "})\n",
    "n_runs = len(params)\n",
    "\n",
    "results = Parallel(n_jobs=4)(\n",
    "    delayed(compare_uplift_proba_dirichlet)(\n",
    "        mu,\n",
    "        params[i][\"A\"],\n",
    "        size,\n",
    "        params[i][\"n_p_0\"],\n",
    "        params[i][\"n_u_0\"],\n",
    "        params[i][\"n_u_0\"]\n",
    "    ) for i in trange(n_runs)\n",
    ")\n",
    "stats = pd.DataFrame.from_records(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81877f00-b720-40ee-98bf-33137c35e416",
   "metadata": {},
   "outputs": [],
   "source": [
    "var = \"mutual_info\"\n",
    "values = np.unique(stats[var])\n",
    "max_value = np.unique(stats.prior_entropy)[0]\n",
    "mu = np.array([0.6, 0.2, 0.1, 0.1])\n",
    "S_0 = mu[1] + mu[3]\n",
    "S_1 = mu[2] + mu[3]\n",
    "\n",
    "show_variance = True\n",
    "\n",
    "def x_tick_formatter(n_u, pos):\n",
    "    if show_variance:\n",
    "        var_0 = S_0 * (1 - S_0) / max(1, n_u)\n",
    "        var_1 = S_1 * (1 - S_1) / max(1, n_u)\n",
    "        return \"{:.0e}\".format(var_0 + var_1)\n",
    "    else:\n",
    "        return str(int(n_u))\n",
    "\n",
    "def y_tick_formatter(n_p, pos):\n",
    "    if show_variance:\n",
    "        return \"{:.0e}\".format(S_0 * (1 - S_0) / max(1, n_p))\n",
    "    else:\n",
    "        return str(int(n_p))\n",
    "\n",
    "cols = 3\n",
    "rows = len(values) // cols\n",
    "fig, axs = plt.subplots(\n",
    "    ncols=cols, nrows=rows,\n",
    "    figsize=(6.5, 4),\n",
    "    layout=\"constrained\",\n",
    "    sharex=True,\n",
    "    sharey=True,\n",
    "    squeeze=False\n",
    ")\n",
    "\n",
    "for i, value in enumerate(values):\n",
    "    row = i // cols\n",
    "    col = i % cols\n",
    "    \n",
    "    s = stats[stats[var] == value]\n",
    "    s = dataframe_to_color_matrix(s, \"n_p_0\", \"n_u_0\", \"best_approach\", cmap)\n",
    "    axs[row, col].imshow(s, interpolation=\"none\")\n",
    "    axs[row, col].xaxis.set_major_formatter(x_tick_formatter)\n",
    "    axs[row, col].yaxis.set_major_formatter(y_tick_formatter)\n",
    "    axs[row, col].set_title(\"${}$% of information\".format(\n",
    "        format_number(100 * value / np.unique(stats.prior_entropy)[0], 1)\n",
    "    ), fontsize=11)\n",
    "    \n",
    "    if row == rows - 1:\n",
    "        axs[row, col].set_xlabel(\"Variance uplift\" if show_variance else \"$n_u$\")\n",
    "    if col == 0:\n",
    "        axs[row, col].set_ylabel(\"Variance predictive\" if show_variance else \"$n_p$\")\n",
    "\n",
    "# Since axes are shared, only one should be inverted to affect all of them\n",
    "axs[0, 0].invert_xaxis()\n",
    "# Hack to have the right legend\n",
    "plt.scatter([], [], c=\"C0\", label=\"Uplift\")\n",
    "plt.scatter([], [], c=\"C1\", label=\"Predictive\")\n",
    "plt.scatter([], [], c=\"C4\", label=\"None\")\n",
    "fig.legend(title=\"Best approach\", frameon=False, loc=\"center left\", bbox_to_anchor=(0.96, 0.84))\n",
    "plt.savefig(\"pdf/n_u_n_p_I.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bda8db-b962-4922-bf45-60c8d95f9bb6",
   "metadata": {},
   "source": [
    "### Impact of the distribution of counterfactuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278d2570-6d81-4052-8c52-241a9eceae44",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1e-2\n",
    "steps_mu = np.array([\n",
    "    [eps, 0.5 - eps, eps, 0.5 - eps],\n",
    "    [eps, eps, 0.5 - eps, 0.5 - eps],\n",
    "    [0.25, 0.25, 0.25, 0.25],\n",
    "    [0.8, 0.1, 0.01, 0.09],\n",
    "    [0.8, 0.01, 0.1, 0.09],\n",
    "    [0.8, 0.01, 0.01, 0.18]\n",
    "])\n",
    "\n",
    "A = 44.43905105200017 # 3%\n",
    "size = 50\n",
    "size = 500000\n",
    "params = ParameterGrid({\n",
    "    \"mu\": steps_mu,\n",
    "    \"n_p_0\": range(1, 51),\n",
    "    \"n_u_0\": range(1, 51)\n",
    "})\n",
    "n_runs = len(params)\n",
    "\n",
    "values = np.zeros((n_runs, 4))\n",
    "for i, v in enumerate(params):\n",
    "    values[i, :] = v[\"mu\"]\n",
    "\n",
    "results = Parallel(n_jobs=4)(\n",
    "    delayed(compare_uplift_proba_dirichlet)(\n",
    "        params[i][\"mu\"],\n",
    "        A,\n",
    "        size,\n",
    "        params[i][\"n_p_0\"],\n",
    "        params[i][\"n_u_0\"],\n",
    "        params[i][\"n_u_0\"]\n",
    "    ) for i in trange(n_runs)\n",
    ")\n",
    "stats = pd.DataFrame.from_records(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b233940d-488b-48f0-b745-990af7f45c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_values = np.array([\n",
    "    [eps, eps, 0.5 - eps, 0.5 - eps],\n",
    "    [0.8, 0.1, 0.01, 0.09],          \n",
    "    [0.25, 0.25, 0.25, 0.25],        \n",
    "    [0.8, 0.01, 0.01, 0.18],          \n",
    "    [eps, 0.5 - eps, eps, 0.5 - eps],\n",
    "    [0.8, 0.01, 0.1, 0.09]         \n",
    "])\n",
    "cols = 3\n",
    "rows = mu_values.shape[0] // cols\n",
    "fig, axs = plt.subplots(\n",
    "    ncols=cols, nrows=rows,\n",
    "    figsize=(6.5, 4),\n",
    "    layout=\"constrained\",\n",
    "    #sharex=True,\n",
    "    #sharey=True,\n",
    "    squeeze=False\n",
    ")\n",
    "\n",
    "show_variance = True\n",
    "\n",
    "def x_tick_formatter(n_u, pos, S_0, S_1):\n",
    "    if show_variance:\n",
    "        var_0 = S_0 * (1 - S_0) / max(1, n_u)\n",
    "        var_1 = S_1 * (1 - S_1) / max(1, n_u)\n",
    "        return \"{:.0e}\".format(var_0 + var_1)\n",
    "    else:\n",
    "        return str(int(n_u))\n",
    "\n",
    "def y_tick_formatter(n_p, pos, S_0):\n",
    "    if show_variance:\n",
    "        return \"{:.0e}\".format(S_0 * (1 - S_0) / max(1, n_p))\n",
    "    else:\n",
    "        return str(int(n_p))\n",
    "    \n",
    "plt.rcParams['axes.titlepad'] = 9\n",
    "\n",
    "for i, mu in enumerate(mu_values):\n",
    "    row = i // cols\n",
    "    col = i % cols\n",
    "    s = stats[(stats.alpha == mu[0])\n",
    "            & (stats.beta  == mu[1])\n",
    "            & (stats.gamma == mu[2])\n",
    "            & (stats.delta == mu[3])\n",
    "    ]\n",
    "    s = dataframe_to_color_matrix(s, \"n_p_0\", \"n_u_0\", \"best_approach\", cmap)\n",
    "    axs[row, col].imshow(s, interpolation=\"none\")\n",
    "    axs[row, col].invert_xaxis()\n",
    "    S_0 = mu[1] + mu[3]\n",
    "    S_1 = mu[2] + mu[3]\n",
    "    axs[row, col].xaxis.set_major_formatter(lambda n, pos, s_0=S_0, s_1=S_1: x_tick_formatter(n, pos, s_0, s_1))\n",
    "    axs[row, col].yaxis.set_major_formatter(lambda n, pos, s_0=S_0: y_tick_formatter(n, pos, s_0))\n",
    "    #axs[row, col].set_title(\"$\\\\beta = {}$%\".format(format_number(mu[1] * 100, 3)))\n",
    "    axs[row, col].set_title(\"$\\\\mu = [{}, {}, {}, {}]$\".format(*[format_number(m, 3) for m in mu]), fontsize=10)\n",
    "    \n",
    "    if row == rows - 1:\n",
    "        axs[row, col].set_xlabel(\"Variance uplift\")\n",
    "    if col == 0:\n",
    "        axs[row, col].set_ylabel(\"Variance predictive\")\n",
    "    \n",
    "# Hack to have the right legend\n",
    "plt.scatter([], [], c=\"C0\", label=\"Uplift\")\n",
    "plt.scatter([], [], c=\"C1\", label=\"Predictive\")\n",
    "fig.legend(title=\"Best approach\", frameon=False, loc=\"center left\", bbox_to_anchor=(0.96, 0.84))\n",
    "plt.savefig(\"pdf/n_u_n_p_mu.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b61be9-8e1e-4c1a-b1e5-0e3ae80232b5",
   "metadata": {},
   "source": [
    "### Impact of the cost-benefit matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d905c5ed-dc66-4f5c-8085-2ed75626e22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.array([0.6, 0.2, 0.1, 0.1])\n",
    "A = 44.43905105200017 # 3%\n",
    "size = 500000\n",
    "steps_CB = np.array([\n",
    "    [[1, 1],     [0, 0]],\n",
    "    [[120, 99],  [0, -1]],\n",
    "    [[120, 60],  [0, -1]],\n",
    "    [[120, 99],  [-30, -40]],\n",
    "    [[120, 60],  [-30, -40]],\n",
    "    [[120, 120],  [-40, -40]]\n",
    "])\n",
    "\n",
    "params = ParameterGrid({\n",
    "    \"CB\": steps_CB,\n",
    "    \"n_p_0\": range(1, 51),\n",
    "    \"n_u_0\": range(1, 51)\n",
    "})\n",
    "n_runs = len(params)\n",
    "\n",
    "\n",
    "results = Parallel(n_jobs=4)(\n",
    "    delayed(compare_uplift_proba_dirichlet)(\n",
    "        mu,\n",
    "        A,\n",
    "        size,\n",
    "        params[i][\"n_p_0\"],\n",
    "        params[i][\"n_u_0\"],\n",
    "        params[i][\"n_u_0\"],\n",
    "        CB=params[i][\"CB\"]\n",
    "    ) for i in trange(n_runs)\n",
    ")\n",
    "stats = pd.DataFrame.from_records(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839162eb-d860-4c59-b9a3-49d9d68aac6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.array([0.6, 0.2, 0.1, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b9727d-3a6e-40b0-873b-bd1d45fa3b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick the order to make it look good\n",
    "CB_values = np.array([\n",
    "    [120,  60,   0,  -1],\n",
    "    [120,  99,   0,  -1],\n",
    "    [  1,   1,   0,   0],\n",
    "    [120,  60, -30, -40],\n",
    "    [120,  99, -30, -40],\n",
    "    [120, 120, -40, -40]\n",
    "])\n",
    "\n",
    "cols = 3\n",
    "rows = CB_values.shape[0] // cols\n",
    "fig, axs = plt.subplots(\n",
    "    ncols=cols, nrows=rows,\n",
    "    figsize=(6.5, 4),\n",
    "    layout=\"constrained\",\n",
    "    sharex=True,\n",
    "    sharey=True,\n",
    "    squeeze=False\n",
    ")\n",
    "S_0 = mu[1] + mu[3]\n",
    "S_1 = mu[2] + mu[3]\n",
    "show_variance = True\n",
    "\n",
    "def x_tick_formatter(n_u, pos):\n",
    "    if show_variance:\n",
    "        var_0 = S_0 * (1 - S_0) / max(1, n_u)\n",
    "        var_1 = S_1 * (1 - S_1) / max(1, n_u)\n",
    "        return \"{:.0e}\".format(var_0 + var_1)\n",
    "    else:\n",
    "        return str(int(n_u))\n",
    "\n",
    "def y_tick_formatter(n_p, pos):\n",
    "    if show_variance:\n",
    "        return \"{:.0e}\".format(S_0 * (1 - S_0) / max(1, n_p))\n",
    "    else:\n",
    "        return str(int(n_p))\n",
    "    \n",
    "plt.rcParams[\"text.usetex\"] = False\n",
    "    \n",
    "for i, CB in enumerate(CB_values):\n",
    "    row = i // cols\n",
    "    col = i % cols\n",
    "    s = stats[\n",
    "        (stats.CB_00 == CB[0])\n",
    "        & (stats.CB_01  == CB[1])\n",
    "        & (stats.CB_10 == CB[2])\n",
    "        & (stats.CB_11 == CB[3])\n",
    "    ]\n",
    "    s = dataframe_to_color_matrix(s, \"n_p_0\", \"n_u_0\", \"best_approach\", cmap)\n",
    "    axs[row, col].imshow(s, interpolation=\"none\")\n",
    "    axs[row, col].xaxis.set_major_formatter(lambda n, pos: x_tick_formatter(n, pos))\n",
    "    axs[row, col].yaxis.set_major_formatter(lambda n, pos: y_tick_formatter(n, pos))\n",
    "    axs[row, col].set_title(\"$\\\\mathrm{{CB}} = [{}; {}; {}; {}]$\".format(*CB), fontsize=10)\n",
    "    \n",
    "    if row == rows - 1:\n",
    "        axs[row, col].set_xlabel(\"Variance uplift\")\n",
    "    if col == 0:\n",
    "        axs[row, col].set_ylabel(\"Variance predictive\")\n",
    "        \n",
    "axs[0, 0].invert_xaxis()\n",
    "# Hack to have the right legend\n",
    "plt.scatter([], [], c=\"C0\", label=\"Uplift\")\n",
    "plt.scatter([], [], c=\"C1\", label=\"Predictive\")\n",
    "fig.legend(title=\"Best approach\", frameon=False, loc=\"center left\", bbox_to_anchor=(0.96, 0.86))\n",
    "plt.savefig(\"pdf/n_u_n_p_cb.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3cf546-65ef-43a0-b70c-96430851fa9e",
   "metadata": {},
   "source": [
    "### Uniform grid in the counterfactual simplex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73bfcd2-f6ee-4d6a-96a5-3835f8190633",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1e-5\n",
    "\n",
    "mu = ParameterGrid({\n",
    "    \"alpha\": np.linspace(eps, 1-eps, 12),\n",
    "    \"beta\": np.linspace(0.01, 1-eps, 12),\n",
    "    \"gamma\": np.linspace(0.01, 1-eps, 12)\n",
    "})\n",
    "\n",
    "mu = pd.DataFrame.from_records(list(mu))\n",
    "mu = mu[mu.alpha + mu.beta + mu.gamma <= 1]\n",
    "mu[\"delta\"] = 1 - mu.alpha - mu.beta - mu.gamma\n",
    "mu = mu.reset_index(drop=True)\n",
    "\n",
    "# With 0.1 increments for the counterfactuals we have 286 values\n",
    "# Let's take 7 steps for the variances, so we have 7 * 7 * 286 = 14014 combinations\n",
    "A = 44.43905105200017 # 3%\n",
    "size = 50\n",
    "size = 500000\n",
    "params = ParameterGrid({\n",
    "    \"mu\": mu.to_numpy(),\n",
    "    \"n_p_0\": range(2, 49, 7), # 7 of increment and 7 values\n",
    "    \"n_u_0\": range(2, 49, 7)  # 7 of increment and 7 values\n",
    "})\n",
    "n_runs = len(params)\n",
    "print(n_runs)\n",
    "\n",
    "if True:\n",
    "    results = Parallel(n_jobs=4)(\n",
    "        delayed(compare_uplift_proba_dirichlet)(\n",
    "            params[i][\"mu\"],\n",
    "            A,\n",
    "            size,\n",
    "            params[i][\"n_p_0\"],\n",
    "            params[i][\"n_u_0\"],\n",
    "            params[i][\"n_u_0\"]\n",
    "        ) for i in trange(n_runs)\n",
    "    )\n",
    "    stats = pd.DataFrame.from_records(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6355306f-a173-4868-be81-94e1c0f7f032",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_values = np.unique(mu.alpha)\n",
    "\n",
    "cols = 4\n",
    "rows = ceil(len(alpha_values) / cols)\n",
    "fig, axs = plt.subplots(\n",
    "    ncols=cols, nrows=rows,\n",
    "    figsize=(7.5, 6),\n",
    "    layout=\"constrained\",\n",
    "    sharex=True,\n",
    "    sharey=True,\n",
    "    squeeze=False\n",
    ")\n",
    "\n",
    "\n",
    "data_to_plot = stats.copy()\n",
    "data_to_plot[\"uplift_best\"] = data_to_plot.best_approach == \"u\"\n",
    "data_to_plot = data_to_plot[[\"alpha\", \"beta\", \"gamma\", \"delta\", \"uplift_best\"]]\n",
    "data_to_plot = data_to_plot.groupby([\"alpha\", \"beta\", \"gamma\", \"delta\"], as_index=False).mean()\n",
    "\n",
    "for i, value in enumerate(alpha_values):\n",
    "    row = i // cols\n",
    "    col = i % cols\n",
    "\n",
    "    s = data_to_plot[data_to_plot.alpha == value]\n",
    "    sc = axs[row, col].scatter(\n",
    "        s.beta,\n",
    "        s.gamma,\n",
    "        c=s.uplift_best,\n",
    "        vmin=0.5,\n",
    "        s=30,\n",
    "        marker=\"s\",\n",
    "        vmax=1\n",
    "    )\n",
    "    axs[row, col].set_title(\"$\\\\alpha = {}$\".format(\n",
    "        format_number(value, 3)\n",
    "    ), fontsize=12)\n",
    "\n",
    "    if row == rows - 1:\n",
    "        axs[row, col].set_xlabel(\"$\\\\beta$\")\n",
    "    if col == 0:\n",
    "        axs[row, col].set_ylabel(\"$\\\\gamma$\")\n",
    "\n",
    "# Since axes are shared, only one should be inverted to affect all of them\n",
    "#axs[0, 0].invert_xaxis()\n",
    "plt.colorbar(sc)\n",
    "#plt.savefig(\"pdf/n_u_n_p_I.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b465e44d-659d-4e1a-8304-9b536e3d23c2",
   "metadata": {},
   "source": [
    "Now, let's show a plot of $S_0$ and $S_1$, where we evaluate to what extent the best approach varies for different values of the counterfactuals, for a given values of $S_0$ and $S_1$. This shows how much just observing the marginal is sufficient or not to understand which approach is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd69d2ee-81ed-44c7-b0b5-a175150559ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (5.5, 4)\n",
    "data_to_plot = stats.copy()\n",
    "data_to_plot[\"uplift_best\"] = data_to_plot.best_approach == \"u\"\n",
    "data_to_plot = data_to_plot[[\"alpha\", \"beta\", \"gamma\", \"delta\", \"uplift_best\"]]\n",
    "data_to_plot = data_to_plot.groupby([\"alpha\", \"beta\", \"gamma\", \"delta\"], as_index=False).mean()\n",
    "data_to_plot[\"S_0\"] = data_to_plot.beta  + data_to_plot.delta\n",
    "data_to_plot[\"S_1\"] = data_to_plot.gamma + data_to_plot.delta\n",
    "#data_to_plot = data_to_plot.groupby([\"S_0\", \"S_1\"], as_index=False)\n",
    "jitter = 0.016\n",
    "dx = np.random.uniform(-jitter, jitter, size=data_to_plot.shape[0])\n",
    "dy = np.random.uniform(-jitter, jitter, size=data_to_plot.shape[0])\n",
    "plt.scatter(\n",
    "    data_to_plot.S_0 + dx,\n",
    "    data_to_plot.S_1 + dy,\n",
    "    c=data_to_plot.uplift_best * 100,\n",
    "    s=50,\n",
    "    vmin=50, vmax=100)\n",
    "plt.xlabel(\"$S_0$\", fontsize=12)\n",
    "plt.ylabel(\"$S_1$\", fontsize=12)\n",
    "cc = plt.colorbar(label=\"Ratio of cases where uplift is better (%)\", pad=0.1)\n",
    "cc.ax.yaxis.tick_left()\n",
    "cc.ax.yaxis.labelpad = 10\n",
    "plt.savefig(\"pdf/S_0_S_1_uplift_better.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aae8c8a-2e7c-4e00-9ddf-4df8df37934c",
   "metadata": {},
   "source": [
    "### Show uplift curves for different situations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9a031e-e2ea-4e90-96b6-7819e27c2c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.array([0.9, 0.05, 0.04, 0.01])\n",
    "prior_entropy = -np.sum(mu * np.log2(mu))\n",
    "\n",
    "steps_A = np.array([\n",
    "    50,\n",
    "    1\n",
    "])\n",
    "size = 500000\n",
    "steps_var_p = np.array([0, 0.1, 0.3])\n",
    "steps_var_u = np.array([0, 0.1, 0.3])\n",
    "\n",
    "nrows = 1\n",
    "ncols = 2\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    nrows=nrows,\n",
    "    ncols=ncols,\n",
    "    figsize=(8, 3),\n",
    "    squeeze=False,\n",
    "    sharex=True\n",
    ")\n",
    "\n",
    "    \n",
    "for i, A in enumerate(steps_A):\n",
    "    a = A * mu\n",
    "    posterior_entropy = digamma(A + 1) - np.sum(digamma(a + 1) * a) / A\n",
    "    \n",
    "    for j, (var_p, var_u) in enumerate(zip(steps_var_p, steps_var_u)):\n",
    "        data = simulate_uplift_ind(a, size, var_p, var_u)\n",
    "\n",
    "        curve_u = cf_uplift_curve(data[\"uplift_hat\"], data[\"uplift\"]).reset_index(drop=True)\n",
    "        curve_p = cf_uplift_curve(data[\"S_0_hat\"], data[\"uplift\"]).reset_index(drop=True)\n",
    "\n",
    "        subsample = np.arange(0, curve_u.shape[0], step=curve_u.shape[0]//5000)\n",
    "        ax = axs[0, i]\n",
    "        line = ax.plot(\n",
    "            curve_u[\"k\"][subsample] / size * 100,\n",
    "            curve_u[\"uplift\"][subsample] * 100,\n",
    "            c=\"C0\"#, alpha=var_u * 2 + 0.4\n",
    "        )\n",
    "        x = [0.56, 0.56, 0.57, 0.36, 0.5, 0.62][i * 3 + j]\n",
    "        y = curve_u[\"uplift\"][x * size] * 100\n",
    "        ax.annotate(str(var_u), xy=(x, y), \n",
    "                    xycoords = ax.get_yaxis_transform(),\n",
    "                    size=12, va=\"center\", color=\"C0\",\n",
    "                    bbox=dict(boxstyle=\"round,pad=0.05,rounding_size=0.5\", fc=\"white\", lw=0))\n",
    "        line = ax.plot(\n",
    "            curve_p[\"k\"][subsample] / size * 100,\n",
    "            curve_p[\"uplift\"][subsample] * 100,\n",
    "            c=\"C1\"#, alpha=var_p * 2 + 0.4\n",
    "        )\n",
    "        x = [0.56, 0.4, 0.73, 0.43, 0.18, 0.32][i * 3 + j]\n",
    "        y = curve_p[\"uplift\"][x * size] * 100\n",
    "        ax.annotate(str(var_p), xy=(x, y), \n",
    "                    xycoords = ax.get_yaxis_transform(),\n",
    "                    size=12, va=\"center\", color=\"C1\",\n",
    "                    bbox=dict(boxstyle=\"round,pad=0.05,rounding_size=0.5\", fc=\"white\", lw=0))\n",
    "    \n",
    "    ax.set_xlabel(\"Treatment rate (%)\")\n",
    "    ax.set_ylabel(\"Uplift (%)\")\n",
    "    ax.set_title(\"$I(X; Y_0, Y_1) = {:.1%}$%\".format((prior_entropy - posterior_entropy) / prior_entropy))\n",
    "    \n",
    "plt.plot([], [], c=\"C0\", label=\"Uplift\")\n",
    "plt.plot([], [], c=\"C1\", label=\"Probabilistic\")\n",
    "fig.legend(title=\"Approach\", frameon=False, loc=\"lower left\", bbox_to_anchor=(0.58, 0.15))\n",
    "plt.savefig(\"pdf/uplift_curves.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "r-cpu.4-1.m89",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/r-cpu.4-1:m89"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
